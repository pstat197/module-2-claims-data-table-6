---
title: "Summary of exploratory tasks"
author: 'Sophie Lian'
date: today
---

### HTML scraping

To determine whether header content improves webpage classification, we extended the HTML scraping process to extract not only paragraph text but also header tags (h1–h6). We applied the same cleaning pipeline to both datasets and used logistic principal component regression (LPCR) to compare predictive performance. Each dataset was transformed using TF–IDF, reduced to 50 principal components, and evaluated with an 80/20 stratified train/test split to ensure a fair comparison.

The results indicate that including header text did not improve predictive accuracy. The LPCR model using only paragraph text achieved an accuracy of 0.547, while the model using both paragraphs and headers decreased slightly to 0.531. This suggests that headers, while potentially informative, were often too inconsistent or sparse across webpages to meaningfully enhance classification. Thus, the additional header text may have introduced noise rather than providing useful signal for the binary prediction task, and therefore we can conclude that including header text did not improve predictive accuracy.

### Bigrams

Do bigrams capture additional information relevant to the classification of interest? Answer the question, **briefly** describe what analysis you conducted to arrive at your answer, and provide quantitative evidence supporting your answer.

### Neural net

For preliminary task 3, we trained a feed-forward neural network on the TF-IDF feature matrix generated from the claim text. After removing constant predictors, the final input dimension included several thousand sparse features. The model architecture consisted of three fully connected hidden layers with 64, 32, and 16 units, respectively, each using ReLU activation to capture nonlinear structure in the high-dimensional text data. To reduce overfitting, an important challenge with TF-IDF inputs, we incorporated dropout (0.15) after the first two layers, which randomly deactivates a portion of neurons during training to improve generalization. The final output layer used a single sigmoid unit to produce a probability for the binary classification task.

The network was trained using the Adam optimizer, which adapts learning rates dynamically during training and is well-suited for large, complex deep learning models. We used binary cross-entropy as the loss function, consistent with the binary nature of the prediction target. Training was performed for 25 epochs with a batch size of 32 and included a 20% validation split to monitor performance during training. 

On the test set, the neural network achieved a predictive accuracy of approximately 0.78, which represents a substantial improvement over the baseline logistic principle component regression model from preliminary task 1 that achieved an accuracy of approximately 0.547. This suggests that the neural network was better able to capture the complex, non-linear patterns present in the TF-IDF values of the claims data. Overall, this improvement highlights the value of deeper architectures and regularization when modeling high dimensional text features, leading to stronger predictive performance and more reliable classification claim outcomes. 
